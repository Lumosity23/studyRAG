# StudyRAG ğŸ“

**Agent RAG local intelligent pour Ã©tudiants** - SystÃ¨me de gÃ©nÃ©ration augmentÃ©e par rÃ©cupÃ©ration utilisant Docling pour le traitement de documents, embeddings locaux, base de donnÃ©es vectorielle et Ollama pour les conversations IA.

## âœ¨ FonctionnalitÃ©s

- ğŸ¤– **Agent conversationnel local** avec Ollama (pas besoin d'OpenAI)
- ğŸ“„ **Traitement multi-format** avec Docling (PDF, Word, PowerPoint, Excel, HTML, Audio)
- ğŸ” **Recherche sÃ©mantique** dans vos documents avec embeddings
- ğŸ’¾ **Base vectorielle** (ChromaDB + PostgreSQL/PGVector)
- ğŸŒ **Interface web moderne** (React/Next.js) + CLI
- ğŸ™ï¸ **Transcription audio** avec Whisper
- ğŸ“š **Citations sources** pour toutes les rÃ©ponses
- ğŸ”„ **Streaming en temps rÃ©el** des rÃ©ponses
- ğŸ  **100% local** - vos donnÃ©es restent privÃ©es

## ğŸš€ DÃ©marrage Ultra-Rapide

### PrÃ©requis
- **Python 3.9+** avec [UV](https://docs.astral.sh/uv/) installÃ©
- **Node.js 18+** et npm (pour l'interface web)
- **Ollama** installÃ© et en cours d'exÃ©cution ([Installation Ollama](https://ollama.ai/))

### Installation en 30 secondes

```bash
# 1. Cloner le projet
git clone <votre-repo>
cd studyrag

# 2. DÃ©marrage automatique (backend + frontend)
python start.py
# OU
./start.sh
```

**C'est tout!** ğŸ‰ Le script fait automatiquement:
- âœ… Installation des dÃ©pendances Python et Node.js
- âœ… Configuration de l'environnement (.env)
- âœ… DÃ©marrage du backend FastAPI
- âœ… DÃ©marrage du frontend React
- âœ… VÃ©rification des services

### AccÃ¨s rapide
- ğŸŒ **Interface web**: http://localhost:3000
- ğŸ”§ **API Backend**: http://localhost:8000
- ğŸ“š **Documentation**: http://localhost:8000/docs
- â¤ï¸ **Health Check**: http://localhost:8000/health

## ğŸ› ï¸ Configuration Manuelle (Optionnelle)

Si vous prÃ©fÃ©rez configurer manuellement:

### 1. Variables d'environnement
```bash
cp .env.example .env
# Ã‰ditez .env selon vos besoins
```

Variables principales:
- `OLLAMA_BASE_URL` - URL d'Ollama (dÃ©faut: http://localhost:11434)
- `LLM_CHOICE` - ModÃ¨le Ollama (dÃ©faut: llama3.2)
- `DATABASE_URL` - Base de donnÃ©es (SQLite par dÃ©faut pour les tests)
- `EMBEDDING_MODEL` - ModÃ¨le d'embeddings local

### 2. Installer Ollama et modÃ¨les
```bash
# Installer Ollama (si pas dÃ©jÃ  fait)
curl -fsSL https://ollama.ai/install.sh | sh

# DÃ©marrer Ollama
ollama serve

# Installer des modÃ¨les (dans un autre terminal)
ollama pull llama3.2        # ModÃ¨le principal recommandÃ©
ollama pull mistral         # Alternative
ollama pull qwen2.5:7b      # Pour plus de performance
```

### 3. Ingestion de documents

Ajoutez vos documents dans le dossier `documents/` ou `test_samples/`:

**Formats supportÃ©s via Docling:**
- ğŸ“„ **PDF** (`.pdf`)
- ğŸ“ **Word** (`.docx`, `.doc`) 
- ğŸ“Š **PowerPoint** (`.pptx`, `.ppt`)
- ğŸ“ˆ **Excel** (`.xlsx`, `.xls`)
- ğŸŒ **HTML** (`.html`, `.htm`)
- ğŸ“‹ **Markdown** (`.md`)
- ğŸ“ƒ **Texte** (`.txt`)
- ğŸµ **Audio** (`.mp3`) - transcription avec Whisper

```bash
# Ingestion automatique
uv run python -m ingestion.ingest --documents documents/

# Avec paramÃ¨tres personnalisÃ©s
uv run python -m ingestion.ingest --documents test_samples/ --chunk-size 800
```

### 4. Utilisation

**Interface Web (RecommandÃ©e)**
- Ouvrez http://localhost:3000
- Interface moderne avec chat, upload de fichiers, gestion des documents

**CLI Interactif**
```bash
uv run python cli.py
```

**API REST**
- Documentation: http://localhost:8000/docs
- Endpoints: `/api/v1/chat`, `/api/v1/documents`, `/api/v1/search`

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚â”€â”€â”€â”€â–¶â”‚   FastAPI        â”‚â”€â”€â”€â”€â–¶â”‚   ChromaDB      â”‚
â”‚  (Next.js)      â”‚     â”‚   Backend        â”‚     â”‚   + PostgreSQL  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                        â”‚             â”‚
                  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  Ollama  â”‚  â”‚ Sentence     â”‚
                  â”‚   LLM    â”‚  â”‚ Transformers â”‚
                  â”‚ (Local)  â”‚  â”‚ (Embeddings) â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                  â”‚ Docling  â”‚
                  â”‚Document  â”‚
                  â”‚Processingâ”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stack Technique
- **Frontend**: React/Next.js avec Tailwind CSS
- **Backend**: FastAPI avec PydanticAI
- **LLM**: Ollama (modÃ¨les locaux)
- **Embeddings**: Sentence Transformers (local)
- **Base vectorielle**: ChromaDB + PostgreSQL/PGVector
- **Traitement docs**: Docling + Whisper
- **DÃ©ploiement**: Docker + Docker Compose

## ğŸ™ï¸ Transcription Audio

Les fichiers audio sont automatiquement transcrits avec **Whisper** via Docling:

**Fonctionnement:**
1. DÃ©posez des fichiers MP3 dans `documents/`
2. Docling utilise Whisper pour la transcription
3. Le texte est indexÃ© et devient recherchable
4. Citations avec timestamps dans les rÃ©ponses

**Avantages:**
- ğŸ™ï¸ **Speech-to-text**: Podcasts, interviews, cours â†’ texte recherchable
- â±ï¸ **Timestamps**: Localisation prÃ©cise du contenu
- ğŸ” **Recherche sÃ©mantique**: Trouvez du contenu audio par sujet
- ğŸ¤– **100% automatique**: Glissez-dÃ©posez et c'est parti

**Exemple de transcription:**
```markdown
[time: 0.0-4.0] Bienvenue dans ce podcast sur l'IA et l'apprentissage automatique.
[time: 5.28-9.96] Aujourd'hui nous discuterons des systÃ¨mes RAG.
```

## ğŸ§© Composants ClÃ©s

### Agent RAG Principal
- **`rag_agent.py`**: Agent conversationnel avec PydanticAI
- **`cli.py`**: Interface en ligne de commande interactive
- **`app/main.py`**: API FastAPI pour l'interface web

### Pipeline d'Ingestion
- **`ingestion/`**: Traitement automatique des documents
- **Docling**: Conversion multi-format (PDF, Office, HTML, Audio)
- **Chunking intelligent**: DÃ©coupage sÃ©mantique optimisÃ©
- **Embeddings locaux**: Sentence Transformers

### Base de DonnÃ©es
- **ChromaDB**: Base vectorielle simple pour les tests
- **PostgreSQL + PGVector**: Base vectorielle scalable
- **SQLite**: Option lÃ©gÃ¨re pour le dÃ©veloppement

### Interface Web
- **Frontend React**: Interface moderne et intuitive
- **Upload de fichiers**: Glisser-dÃ©poser direct
- **Chat en temps rÃ©el**: Streaming des rÃ©ponses
- **Gestion des documents**: Visualisation et organisation

## âš¡ Optimisations

### Performance
- **Cache des embeddings**: RÃ©duction des calculs rÃ©pÃ©titifs
- **Pool de connexions**: Gestion optimisÃ©e de la base de donnÃ©es
- **Streaming**: RÃ©ponses en temps rÃ©el token par token
- **Chunking adaptatif**: Taille optimisÃ©e selon le type de document

### SÃ©curitÃ© et ConfidentialitÃ©
- **100% local**: Aucune donnÃ©e envoyÃ©e vers des services externes
- **Ollama local**: LLM qui tourne sur votre machine
- **Embeddings locaux**: Sentence Transformers sans API
- **DonnÃ©es privÃ©es**: Vos documents restent sur votre systÃ¨me

## ğŸ³ DÃ©ploiement Docker

### DÃ©marrage avec Docker Compose

```bash
# DÃ©marrer tous les services
docker-compose up -d

# Ingestion de documents
docker-compose --profile ingestion up ingestion

# Voir les logs
docker-compose logs -f rag-agent
```

### DÃ©ploiement Production
```bash
# Build optimisÃ©
docker build -t studyrag:prod .

# Lancement avec variables d'environnement
docker run -d \
  -e OLLAMA_BASE_URL=http://ollama:11434 \
  -e DATABASE_URL=postgresql://... \
  -p 8000:8000 \
  studyrag:prod
```

## ğŸ“š Tutoriels et Exemples

### ğŸ“ Nouveau avec Docling?

**Commencez par les tutoriels!** Consultez le dossier [`docling_basics/`](./docling_basics/) pour des exemples progressifs:

1. **Conversion PDF simple** - Traitement de base des documents
2. **Support multi-format** - PDF, Word, PowerPoint
3. **Transcription audio** - Speech-to-text avec Whisper
4. **Chunking hybride** - DÃ©coupage intelligent pour RAG

### API REST

**Endpoints principaux:**
- `POST /api/v1/chat` - Conversation avec l'agent
- `POST /api/v1/documents/upload` - Upload de documents
- `GET /api/v1/documents` - Liste des documents
- `POST /api/v1/search` - Recherche sÃ©mantique
- `GET /health` - Statut des services

**Documentation complÃ¨te:** http://localhost:8000/docs

## ğŸ“ Structure du Projet

```
studyrag/
â”œâ”€â”€ start.py                 # ğŸš€ Script de dÃ©marrage automatique
â”œâ”€â”€ start.sh                 # ğŸš€ Script bash alternatif
â”œâ”€â”€ cli.py                   # ğŸ’¬ Interface CLI interactive
â”œâ”€â”€ rag_agent.py             # ğŸ¤– Agent RAG principal
â”œâ”€â”€ main.py                  # ğŸ“„ Point d'entrÃ©e legacy
â”œâ”€â”€ app/                     # ğŸŒ Backend FastAPI
â”‚   â”œâ”€â”€ main.py              # API principale
â”‚   â”œâ”€â”€ api/                 # Endpoints REST
â”‚   â”œâ”€â”€ core/                # Configuration et middleware
â”‚   â”œâ”€â”€ models/              # ModÃ¨les de donnÃ©es
â”‚   â””â”€â”€ services/            # Services mÃ©tier
â”œâ”€â”€ frontend/                # âš›ï¸ Interface React/Next.js
â”‚   â”œâ”€â”€ src/                 # Code source React
â”‚   â”œâ”€â”€ components/          # Composants UI
â”‚   â”œâ”€â”€ pages/               # Pages Next.js
â”‚   â””â”€â”€ package.json         # DÃ©pendances Node.js
â”œâ”€â”€ ingestion/               # ğŸ“¥ Pipeline d'ingestion
â”‚   â”œâ”€â”€ ingest.py            # Script principal
â”‚   â”œâ”€â”€ embedder.py          # GÃ©nÃ©ration d'embeddings
â”‚   â””â”€â”€ chunker.py           # DÃ©coupage de documents
â”œâ”€â”€ utils/                   # ğŸ”§ Modules utilitaires
â”‚   â”œâ”€â”€ providers.py         # Configuration Ollama/modÃ¨les
â”‚   â”œâ”€â”€ db_utils.py          # Gestion base de donnÃ©es
â”‚   â””â”€â”€ models.py            # ModÃ¨les Pydantic
â”œâ”€â”€ documents/               # ğŸ“š Vos documents Ã  traiter
â”œâ”€â”€ test_samples/            # ğŸ“‹ Fichiers d'exemple
â”œâ”€â”€ docling_basics/          # ğŸ“ Tutoriels Docling
â”œâ”€â”€ scripts/                 # ğŸ§ª Scripts de test et debug
â”œâ”€â”€ docs/                    # ğŸ“– Documentation
â”œâ”€â”€ sql/                     # ğŸ—„ï¸ SchÃ©mas base de donnÃ©es
â”œâ”€â”€ pyproject.toml           # ğŸ“¦ Configuration Python/UV
â”œâ”€â”€ docker-compose.yml       # ğŸ³ DÃ©ploiement Docker
â””â”€â”€ README.md                # ğŸ“„ Ce fichier
```

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©ez votre branche (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ†˜ Support

- ğŸ“– **Documentation**: Consultez le dossier `docs/`
- ğŸ› **Issues**: Ouvrez une issue sur GitHub
- ğŸ’¬ **Discussions**: Utilisez les GitHub Discussions
- ğŸ“§ **Contact**: [votre-email]

---

**StudyRAG** - Votre assistant IA local pour l'apprentissage et la recherche documentaire ğŸ“âœ¨