#!/usr/bin/env python3
"""
Test de diff√©rents mod√®les d'embedding pour am√©liorer la qualit√© RAG
"""

import asyncio
import time
from typing import List, Dict, Any
from rich.console import Console
from rich.table import Table
from rich.progress import track
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

console = Console()

class EmbeddingModelTester:
    """Teste diff√©rents mod√®les d'embedding"""
    
    def __init__(self):
        # Mod√®les √† tester (du plus l√©ger au plus performant)
        self.models_to_test = {
            # Mod√®les l√©gers et rapides
            "all-MiniLM-L6-v2": {
                "description": "L√©ger, rapide (384 dim)",
                "size": "80MB",
                "languages": "Multilingue"
            },
            "all-MiniLM-L12-v2": {
                "description": "√âquilibr√© (384 dim)", 
                "size": "120MB",
                "languages": "Multilingue"
            },
            
            # Mod√®les fran√ßais sp√©cialis√©s
            "dangvantuan/sentence-camembert-large": {
                "description": "Sp√©cialis√© fran√ßais (1024 dim)",
                "size": "440MB", 
                "languages": "Fran√ßais"
            },
            
            # Mod√®les multilingues performants
            "paraphrase-multilingual-MiniLM-L12-v2": {
                "description": "Multilingue performant (384 dim)",
                "size": "120MB",
                "languages": "50+ langues"
            },
            
            # Mod√®les de derni√®re g√©n√©ration
            "sentence-transformers/all-mpnet-base-v2": {
                "description": "Tr√®s performant anglais (768 dim)",
                "size": "420MB",
                "languages": "Anglais"
            },
            
            # Mod√®les Gemma/Google (si disponibles)
            "google/gemma-2b": {
                "description": "Gemma 2B (si compatible)",
                "size": "5GB",
                "languages": "Multilingue",
                "note": "N√©cessite adaptation"
            }
        }
        
        # Queries de test en fran√ßais (domaine √©tudiant)
        self.test_queries = [
            "Quelles sont les caract√©ristiques techniques de l'ESP32?",
            "Comment programmer un microcontr√¥leur?", 
            "Qu'est-ce que le machine learning?",
            "Expliquer les algorithmes de classification",
            "Architecture des r√©seaux de neurones",
            "D√©veloppement web avec JavaScript",
            "Bases de donn√©es relationnelles",
            "S√©curit√© informatique et cryptographie"
        ]
        
        # Documents de test (extraits de notre base)
        self.test_documents = [
            "L'ESP32 est un microcontr√¥leur d√©velopp√© par Espressif Systems. Il int√®gre WiFi et Bluetooth dans un seul chip.",
            "Le Machine Learning (ML) est une branche de l'intelligence artificielle qui permet aux machines d'apprendre automatiquement.",
            "JavaScript est utilis√© pour le d√©veloppement web c√¥t√© client et serveur avec Node.js.",
            "Les r√©seaux de neurones sont compos√©s de couches de neurones artificiels connect√©s entre eux.",
            "La classification consiste √† pr√©dire des cat√©gories ou classes discr√®tes √† partir de donn√©es.",
            "Les bases de donn√©es relationnelles organisent les donn√©es en tables avec des relations entre elles.",
            "La cryptographie prot√®ge les informations en les transformant en code secret.",
            "Arduino IDE est un environnement de d√©veloppement pour programmer les microcontr√¥leurs."
        ]
    
    def load_model_safe(self, model_name: str) -> tuple:
        """Charge un mod√®le de mani√®re s√©curis√©e"""
        try:
            console.print(f"[cyan]Chargement de {model_name}...[/cyan]")
            start_time = time.time()
            
            model = SentenceTransformer(model_name)
            load_time = time.time() - start_time
            
            # Test rapide pour obtenir les dimensions
            test_embedding = model.encode("test")
            dimensions = len(test_embedding)
            
            console.print(f"[green]‚úì {model_name} charg√© ({dimensions}D, {load_time:.1f}s)[/green]")
            return model, dimensions, load_time, None
            
        except Exception as e:
            console.print(f"[red]‚úó Erreur avec {model_name}: {e}[/red]")
            return None, 0, 0, str(e)
    
    def evaluate_model_performance(self, model, model_name: str) -> Dict[str, Any]:
        """√âvalue les performances d'un mod√®le"""
        console.print(f"[blue]√âvaluation de {model_name}...[/blue]")
        
        # Encode les documents et queries
        start_time = time.time()
        doc_embeddings = model.encode(self.test_documents)
        query_embeddings = model.encode(self.test_queries)
        encoding_time = time.time() - start_time
        
        # Calcule les similarit√©s
        similarities = cosine_similarity(query_embeddings, doc_embeddings)
        
        # M√©triques de qualit√©
        results = {
            "encoding_time": encoding_time,
            "avg_similarity": np.mean(similarities),
            "max_similarity": np.max(similarities),
            "min_similarity": np.min(similarities),
            "std_similarity": np.std(similarities)
        }
        
        # Trouve les meilleures correspondances pour chaque query
        best_matches = []
        for i, query in enumerate(self.test_queries):
            best_doc_idx = np.argmax(similarities[i])
            best_similarity = similarities[i][best_doc_idx]
            best_matches.append({
                "query": query[:50] + "...",
                "best_doc": self.test_documents[best_doc_idx][:50] + "...",
                "similarity": best_similarity
            })
        
        results["best_matches"] = best_matches
        return results
    
    async def run_comparison(self):
        """Lance la comparaison des mod√®les"""
        console.print("[bold blue]üß™ COMPARAISON DES MOD√àLES D'EMBEDDING[/bold blue]")
        console.print()
        
        results = {}
        
        # Teste chaque mod√®le
        for model_name, info in self.models_to_test.items():
            console.print(f"[yellow]üìä Test: {model_name}[/yellow]")
            console.print(f"   Description: {info['description']}")
            console.print(f"   Taille: {info['size']}")
            console.print()
            
            # Charge le mod√®le
            model, dimensions, load_time, error = self.load_model_safe(model_name)
            
            if model is None:
                results[model_name] = {
                    "error": error,
                    "status": "failed"
                }
                console.print()
                continue
            
            # √âvalue les performances
            try:
                performance = self.evaluate_model_performance(model, model_name)
                
                results[model_name] = {
                    "status": "success",
                    "dimensions": dimensions,
                    "load_time": load_time,
                    "info": info,
                    "performance": performance
                }
                
                console.print(f"[green]‚úì √âvaluation termin√©e[/green]")
                
            except Exception as e:
                console.print(f"[red]‚úó Erreur d'√©valuation: {e}[/red]")
                results[model_name] = {
                    "error": str(e),
                    "status": "eval_failed"
                }
            
            console.print()
        
        # Affiche les r√©sultats
        self.display_results(results)
        
        return results
    
    def display_results(self, results: Dict[str, Any]):
        """Affiche les r√©sultats de comparaison"""
        console.print("[bold green]üìä R√âSULTATS DE LA COMPARAISON[/bold green]")
        console.print()
        
        # Tableau de comparaison
        table = Table(title="Comparaison des mod√®les d'embedding")
        table.add_column("Mod√®le", style="cyan")
        table.add_column("Status", style="green")
        table.add_column("Dimensions", style="yellow")
        table.add_column("Temps chargement", style="blue")
        table.add_column("Temps encoding", style="blue")
        table.add_column("Similarit√© moy.", style="magenta")
        table.add_column("Recommandation", style="bold")
        
        successful_models = []
        
        for model_name, result in results.items():
            if result["status"] == "success":
                perf = result["performance"]
                
                # Calcule un score global
                score = (
                    perf["avg_similarity"] * 0.4 +  # Qualit√© des embeddings
                    (1 / (perf["encoding_time"] + 1)) * 0.3 +  # Vitesse
                    (1 / (result["load_time"] + 1)) * 0.3  # Temps de chargement
                )
                
                successful_models.append((model_name, score, result))
                
                # Recommandation bas√©e sur le score
                if score > 0.7:
                    recommendation = "üèÜ Excellent"
                elif score > 0.5:
                    recommendation = "‚úÖ Bon"
                elif score > 0.3:
                    recommendation = "‚ö†Ô∏è Moyen"
                else:
                    recommendation = "‚ùå Faible"
                
                table.add_row(
                    model_name.split("/")[-1],
                    "‚úÖ OK",
                    str(result["dimensions"]),
                    f"{result['load_time']:.1f}s",
                    f"{perf['encoding_time']:.2f}s",
                    f"{perf['avg_similarity']:.3f}",
                    recommendation
                )
            else:
                table.add_row(
                    model_name.split("/")[-1],
                    "‚ùå √âchec",
                    "-",
                    "-",
                    "-",
                    "-",
                    "Non test√©"
                )
        
        console.print(table)
        console.print()
        
        # Recommandations
        if successful_models:
            # Trie par score
            successful_models.sort(key=lambda x: x[1], reverse=True)
            best_model = successful_models[0]
            
            console.print("[bold green]üéØ RECOMMANDATIONS:[/bold green]")
            console.print(f"üèÜ **Meilleur mod√®le**: {best_model[0]}")
            console.print(f"   Score: {best_model[1]:.3f}")
            console.print(f"   Dimensions: {best_model[2]['dimensions']}")
            console.print(f"   Similarit√© moyenne: {best_model[2]['performance']['avg_similarity']:.3f}")
            console.print()
            
            console.print("üìã **Pour votre usage**:")
            console.print("‚Ä¢ **L√©ger et rapide**: all-MiniLM-L6-v2 (actuel)")
            console.print("‚Ä¢ **√âquilibr√©**: paraphrase-multilingual-MiniLM-L12-v2")
            console.print("‚Ä¢ **Fran√ßais sp√©cialis√©**: sentence-camembert-large")
            console.print("‚Ä¢ **Maximum performance**: all-mpnet-base-v2")


async def main():
    """Fonction principale"""
    tester = EmbeddingModelTester()
    await tester.run_comparison()
    
    console.print()
    console.print("[bold blue]üí° CONSEILS POUR AM√âLIORER VOTRE RAG:[/bold blue]")
    console.print()
    console.print("1. **Plus de donn√©es = meilleurs r√©sultats**")
    console.print("   ‚Ä¢ Ajoutez plus de documents dans votre domaine")
    console.print("   ‚Ä¢ Diversifiez les sources (cours, articles, docs techniques)")
    console.print()
    console.print("2. **Fine-tuning** (avanc√©)")
    console.print("   ‚Ä¢ Cr√©ez des paires question-r√©ponse de votre domaine")
    console.print("   ‚Ä¢ Utilisez sentence-transformers pour fine-tuner")
    console.print()
    console.print("3. **Chunking intelligent**")
    console.print("   ‚Ä¢ Testez diff√©rentes tailles de chunks (200-500 chars)")
    console.print("   ‚Ä¢ Ajoutez plus d'overlap entre chunks")
    console.print()
    console.print("4. **Recherche hybride**")
    console.print("   ‚Ä¢ Combinez recherche s√©mantique + recherche par mots-cl√©s")
    console.print("   ‚Ä¢ Utilisez le re-ranking des r√©sultats")


if __name__ == "__main__":
    asyncio.run(main())