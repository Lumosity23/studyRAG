#!/usr/bin/env python3
"""
Upgrade du syst√®me d'embeddings pour am√©liorer la qualit√© RAG
"""

import asyncio
import os
from pathlib import Path
from rich.console import Console
from rich.prompt import Confirm, Prompt
from dotenv import load_dotenv

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.chroma_db import create_chroma_db
from ingest_simple import StudyRAGIngestion

load_dotenv()
console = Console()

class EmbeddingUpgrader:
    """Upgrade le syst√®me d'embeddings"""
    
    def __init__(self):
        self.available_models = {
            "1": {
                "name": "all-MiniLM-L6-v2",
                "description": "L√©ger et rapide (384D) - ACTUEL",
                "pros": ["Tr√®s rapide", "Faible m√©moire", "Bon pour d√©buter"],
                "cons": ["Qualit√© moyenne"]
            },
            "2": {
                "name": "all-MiniLM-L12-v2", 
                "description": "√âquilibr√© (384D)",
                "pros": ["Bon compromis vitesse/qualit√©", "M√™me dimension"],
                "cons": ["Plus lent au chargement"]
            },
            "3": {
                "name": "paraphrase-multilingual-MiniLM-L12-v2",
                "description": "Multilingue performant (384D)",
                "pros": ["Excellent pour le fran√ßais", "50+ langues", "M√™me dimension"],
                "cons": ["Plus lent", "Plus gros"]
            },
            "4": {
                "name": "sentence-transformers/all-mpnet-base-v2",
                "description": "Maximum performance (768D)",
                "pros": ["Meilleure qualit√©", "√âtat de l'art"],
                "cons": ["Plus lent", "Plus de m√©moire", "Dimensions diff√©rentes"]
            }
        }
    
    def display_model_options(self):
        """Affiche les options de mod√®les"""
        console.print("[bold blue]üöÄ UPGRADE DU SYST√àME D'EMBEDDINGS[/bold blue]")
        console.print()
        console.print("Mod√®les disponibles :")
        console.print()
        
        for key, model in self.available_models.items():
            console.print(f"[cyan]{key}. {model['name']}[/cyan]")
            console.print(f"   {model['description']}")
            console.print(f"   ‚úÖ Avantages: {', '.join(model['pros'])}")
            console.print(f"   ‚ö†Ô∏è  Inconv√©nients: {', '.join(model['cons'])}")
            console.print()
    
    def update_env_file(self, new_model: str):
        """Met √† jour le fichier .env avec le nouveau mod√®le"""
        env_path = Path(".env")
        
        if env_path.exists():
            # Lit le fichier actuel
            with open(env_path, 'r') as f:
                lines = f.readlines()
            
            # Met √† jour la ligne EMBEDDING_MODEL
            updated = False
            for i, line in enumerate(lines):
                if line.startswith("EMBEDDING_MODEL="):
                    lines[i] = f"EMBEDDING_MODEL={new_model}\n"
                    updated = True
                    break
            
            # Ajoute la ligne si elle n'existe pas
            if not updated:
                lines.append(f"EMBEDDING_MODEL={new_model}\n")
            
            # √âcrit le fichier mis √† jour
            with open(env_path, 'w') as f:
                f.writelines(lines)
            
            console.print(f"[green]‚úì Fichier .env mis √† jour avec {new_model}[/green]")
        else:
            console.print("[red]‚ùå Fichier .env non trouv√©[/red]")
    
    async def re_ingest_with_new_model(self, documents_folder: str = "documents"):
        """Re-ing√®re les documents avec le nouveau mod√®le"""
        console.print("[yellow]üîÑ Re-ingestion des documents avec le nouveau mod√®le...[/yellow]")
        
        # Cr√©e une nouvelle instance d'ingestion
        ingestion = StudyRAGIngestion(documents_folder=documents_folder)
        
        try:
            # Lance l'ingestion (qui va vider et re-remplir la base)
            result = await ingestion.ingest_all(clear_existing=True)
            
            if result["success"]:
                console.print(f"[green]‚úÖ Re-ingestion r√©ussie![/green]")
                console.print(f"   ‚Ä¢ {result['successful']} documents trait√©s")
                console.print(f"   ‚Ä¢ {result['total_chunks']} chunks cr√©√©s")
                return True
            else:
                console.print(f"[red]‚ùå √âchec de la re-ingestion[/red]")
                return False
                
        except Exception as e:
            console.print(f"[red]‚ùå Erreur lors de la re-ingestion: {e}[/red]")
            return False
        finally:
            await ingestion.close()
    
    async def test_new_model(self):
        """Teste le nouveau mod√®le avec quelques requ√™tes"""
        console.print("[cyan]üß™ Test du nouveau mod√®le...[/cyan]")
        
        try:
            from chat_rag import StudyRAGChat
            
            chat = StudyRAGChat()
            
            test_queries = [
                "Quelles sont les caract√©ristiques de l'ESP32?",
                "Comment fonctionne le machine learning?",
                "Qu'est-ce qu'un microcontr√¥leur?"
            ]
            
            console.print("Tests de recherche :")
            for query in test_queries:
                console.print(f"[dim]Query: {query}[/dim]")
                
                results = await chat.search_knowledge_base(query, limit=3)
                
                if results:
                    best_similarity = max(r['similarity'] for r in results)
                    console.print(f"[green]‚úì {len(results)} r√©sultats, meilleure similarit√©: {best_similarity:.3f}[/green]")
                else:
                    console.print("[red]‚úó Aucun r√©sultat[/red]")
            
            await chat.close()
            console.print("[green]‚úÖ Test termin√©[/green]")
            
        except Exception as e:
            console.print(f"[red]‚ùå Erreur lors du test: {e}[/red]")
    
    async def run_upgrade(self):
        """Lance le processus d'upgrade"""
        self.display_model_options()
        
        # Choix du mod√®le
        choice = Prompt.ask(
            "Choisissez un mod√®le",
            choices=list(self.available_models.keys()),
            default="3"
        )
        
        selected_model = self.available_models[choice]
        console.print(f"\n[green]Mod√®le s√©lectionn√©: {selected_model['name']}[/green]")
        
        # Confirmation
        if not Confirm.ask(f"Voulez-vous upgrader vers {selected_model['name']} ?"):
            console.print("[yellow]Upgrade annul√©[/yellow]")
            return
        
        # Avertissement pour les mod√®les avec dimensions diff√©rentes
        if choice == "4":  # all-mpnet-base-v2
            console.print("[yellow]‚ö†Ô∏è Ce mod√®le utilise 768 dimensions au lieu de 384.[/yellow]")
            console.print("[yellow]   Tous les documents devront √™tre re-ing√©r√©s.[/yellow]")
            
            if not Confirm.ask("Continuer ?"):
                console.print("[yellow]Upgrade annul√©[/yellow]")
                return
        
        # Met √† jour le fichier .env
        self.update_env_file(selected_model["name"])
        
        # Re-ingestion n√©cessaire
        console.print()
        if Confirm.ask("Voulez-vous re-ing√©rer les documents maintenant ?", default=True):
            success = await self.re_ingest_with_new_model()
            
            if success:
                # Test du nouveau mod√®le
                console.print()
                if Confirm.ask("Voulez-vous tester le nouveau mod√®le ?", default=True):
                    await self.test_new_model()
                
                console.print()
                console.print("[bold green]üéâ Upgrade termin√© avec succ√®s ![/bold green]")
                console.print(f"[green]Nouveau mod√®le: {selected_model['name']}[/green]")
                console.print("[green]Vous pouvez maintenant utiliser le chat RAG am√©lior√©[/green]")
            else:
                console.print("[red]‚ùå √âchec de l'upgrade[/red]")
        else:
            console.print("[yellow]‚ö†Ô∏è N'oubliez pas de re-ing√©rer vos documents :[/yellow]")
            console.print("[yellow]python ingest_simple.py[/yellow]")


async def main():
    """Fonction principale"""
    upgrader = EmbeddingUpgrader()
    await upgrader.run_upgrade()


if __name__ == "__main__":
    asyncio.run(main())